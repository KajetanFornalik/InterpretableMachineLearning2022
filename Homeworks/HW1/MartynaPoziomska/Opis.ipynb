{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('braindecode_lazy'):\n",
    "    !git clone https://github.com/gemeinl/braindecode_lazy\n",
    "    import subprocess\n",
    "    subprocess.check_output('cd braindecode_lazy; git reset --hard c785237e03f6cb0d10a3d68690a6d7111b90e994; exit 0', stderr=subprocess.STDOUT, shell=True) \n",
    "    # Ręcznie trzeba zmienić nazwę:\n",
    "    with open('braindecode_lazy/braindecode_lazy/datasets/tuh.py', 'r') as f:\n",
    "        p = f.read()\n",
    "    p = p.replace('read_all_file_names', '_read_all_file_names')\n",
    "    with open('braindecode_lazy/braindecode_lazy/datasets/tuh.py', 'w') as f:\n",
    "        f.write(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dmj/fizmed/mpoziomska/.pyenv/versions/3.6.10/envs/HW1/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"braindecode_lazy/\")\n",
    "from braindecode_lazy.datasets.tuh import Tuh\n",
    "from braindecode_lazy.experiments.monitors_lazy_loading import compute_preds_per_trial\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "from braindecode.experiments.experiment import Experiment\n",
    "\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dwa pliki były za ciężkie dla githuba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/eval'):\n",
    "    if not os.path.exists('data/large_files.zip'):\n",
    "        import gdown\n",
    "        url = 'https://www.fuw.edu.pl/~mpoziomska/data/large_files.zip'\n",
    "        output = 'data/'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "    from zipfile import ZipFile\n",
    "    with ZipFile('data/large_files.zip', 'r') as zipObj:\n",
    "        zipObj.extractall('data')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - sieć Shallow\n",
    "Nie zdążyłam uporządkować kodów, więc na osobnym repozytorium znajduje się kod do trenowania tego modelu: https://github.com/mpoziomska/Explain_pathological_eeg/blob/master/run_model.py. Tutaj mam wgrany jedynie gotowy model i przetestuję go na małym zbiorze ewaluacyjnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12043353716532389\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "test_subset = Tuh(f\"data/eval/\", target='pathological')\n",
    "print((time.time() - t0) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "input_time_length = 6000\n",
    "seed = 1\n",
    "n_chans = 21\n",
    "remember_best_column = \"valid_misclass\"\n",
    "model = torch.load('model_1.pt')\n",
    "test_input = np_to_var(np.ones((2, n_chans, input_time_length, 1), dtype='float32')).to(device)\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "\n",
    "exp = Experiment(\n",
    "        model=model,\n",
    "        train_set=None,\n",
    "        valid_set=None,\n",
    "        test_set=test_subset,\n",
    "        iterator=CropsFromTrialsIterator(batch_size, input_time_length, n_preds_per_input, seed),\n",
    "        loss_function=None,\n",
    "        optimizer=None,\n",
    "        model_constraint=None,\n",
    "        monitors=None,\n",
    "        stop_criterion=None,\n",
    "        remember_best_column=remember_best_column,\n",
    "        run_after_early_stop=False,\n",
    "        batch_modifier=None,\n",
    "        do_early_stop=False,\n",
    "        reset_after_second_run=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation acc: 0.8214285714285714, mcc: 0.5307910421576296\n"
     ]
    }
   ],
   "source": [
    "def make_final_predictions(exp, device):\n",
    "    exp.model.eval()\n",
    "    setname = 'test'\n",
    "    dataset = exp.datasets[setname]\n",
    "    preds_per_batch = [var_to_np(exp.model(np_to_var(b[0]).to(device)))\n",
    "                       for b in exp.iterator.get_batches(dataset,\n",
    "                                                         shuffle=False)]\n",
    "    preds_per_trial = compute_preds_per_trial(\n",
    "        preds_per_batch, dataset,\n",
    "        input_time_length=exp.iterator.input_time_length,\n",
    "        n_stride=exp.iterator.n_preds_per_input)\n",
    "    mean_preds_per_trial = [np.mean(preds, axis=(0, 2)) for preds in\n",
    "                            preds_per_trial]\n",
    "    mean_preds_per_trial = np.array(mean_preds_per_trial)\n",
    "    return mean_preds_per_trial, dataset.y\n",
    "        \n",
    "mean_preds_per_trial, y = make_final_predictions(exp, device)\n",
    "preds = np.argmax(mean_preds_per_trial, axis=1)\n",
    "acc = np.sum(preds == y) / len(y)\n",
    "\n",
    "mcc = matthews_corrcoef(y, preds)\n",
    "print(f\"Evaluation acc: {acc}, mcc: {mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemannian-geometry\n",
    "Model korzysta z macierzy kowariancji między kanałami EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimedTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer=transformer\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        t = time.time()\n",
    "        return_value = self.transformer.fit(X=X, y=y)\n",
    "        print(\"{} fitting time: {:.2f}s\".format(self.transformer.__repr__, time.time() - t))\n",
    "        return return_value\n",
    "    \n",
    "    def transform(self, X):\n",
    "        t = time.time()\n",
    "        return_value = self.transformer.transform(X=X)\n",
    "        print(\"{} transforming time: {:.2f}s\".format(self.transformer.__repr__, time.time() - t))\n",
    "        return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_acc(pred_df):\n",
    "    accs = []\n",
    "    for i, d in pred_df.groupby(\"id\"):\n",
    "        accs.append((d.y_pred == d.y_true).mean())\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> fitting time: 6.12s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.44s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.44s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.05s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.05s\n",
      "ACC dla zbioru treningowego: 0.8656111929307806, dla zbioru ewaluacyjnego: 0.8586956521739131\n"
     ]
    }
   ],
   "source": [
    "kernel=\"rbf\"\n",
    "adaptation = False\n",
    "C = 10\n",
    "pipe = Pipeline([\n",
    "    (\"ts\", TimedTransformer(TangentSpace(tsupdate=adaptation, metric=\"riemann\"))),\n",
    "    (\"clf\", SVC(kernel=kernel, C=C, probability=True, gamma=\"auto\"))\n",
    "])\n",
    "\n",
    "train_X = np.load(\"data/mean_train_covs.npy\")\n",
    "train_y = np.load(\"data/train_pathology_labels.npy\")\n",
    "test_X = np.load(\"data/mean_eval_covs.npy\")\n",
    "test_y = np.load(\"data/eval_pathology_labels.npy\")\n",
    "fold_i = 1\n",
    "pipe.fit(train_X, train_y)\n",
    "probas_train = pipe.predict_proba(train_X)\n",
    "preds_train = pipe.predict(train_X)\n",
    "train_preds, test_preds, train_probas, test_probas = pd.DataFrame(),pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "column_names = [\"id\", \"y_pred\", \"y_true\"]\n",
    "tmp = pd.DataFrame([len(train_y) * [fold_i], probas_train[:, 1], train_y], index=column_names).T\n",
    "train_probas = train_probas.append(tmp, ignore_index=True)  \n",
    "\n",
    "tmp2 = pd.DataFrame([len(train_y) * [fold_i], preds_train, train_y], index=column_names).T\n",
    "train_preds = train_preds.append(tmp2, ignore_index=True)  \n",
    "\n",
    "probas_test = pipe.predict_proba(test_X)\n",
    "preds_test = pipe.predict(test_X)\n",
    "\n",
    "tmp = pd.DataFrame([len(test_y) * [fold_i], probas_test[:, 1], test_y], index=column_names).T\n",
    "test_probas = test_probas.append(tmp, ignore_index=True)  \n",
    "\n",
    "tmp2 = pd.DataFrame([len(test_y) * [fold_i], preds_test, test_y], index=column_names).T\n",
    "test_preds = test_preds.append(tmp2, ignore_index=True)  \n",
    "\n",
    "print(f\"ACC dla zbioru treningowego: {mean_acc(train_preds)}, dla zbioru ewaluacyjnego: {mean_acc(test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
