{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'braindecode_lazy'...\n",
      "remote: Enumerating objects: 453, done.\u001b[K\n",
      "remote: Total 453 (delta 0), reused 0 (delta 0), pack-reused 453\u001b[K\n",
      "Receiving objects: 100% (453/453), 13.66 MiB | 16.24 MiB/s, done.\n",
      "Resolving deltas: 100% (220/220), done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/gemeinl/braindecode_lazy\n",
    "    \n",
    "import numpy as np\n",
    "import torch \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "import sys\n",
    "from braindecode_lazy.datasets.tuh import Tuh\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "from braindecode.experiments.experiment import Experiment\n",
    "\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - sieć Shallow\n",
    "Nie zdążyłam uporządkować kodów, więc na osobnym repozytorium znajduje się kod do trenowania tego modelu: https://github.com/mpoziomska/Explain_pathological_eeg/blob/master/run_model.py. Tutaj mam wgrany jedynie gotowy model i przetestuję go na zbiorze ewaluacyjnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.225489854812622\n"
     ]
    }
   ],
   "source": [
    "# to się powinno załadować w ok. 3 min\n",
    "t0 = time.time()\n",
    "test_subset = Tuh(f\"data/eval/\", target='pathological')\n",
    "print((time.time() - t0) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_time_length = 6000\n",
    "seed = 1\n",
    "n_chans = 21\n",
    "remember_best_column = \"valid_misclass\"\n",
    "model = torch.load('model_1.pt')\n",
    "test_input = np_to_var(np.ones((2, n_chans, input_time_length, 1), dtype='float32')).to(device)\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "\n",
    "exp = Experiment(\n",
    "        model=model,\n",
    "        train_set=None,\n",
    "        valid_set=None,\n",
    "        test_set=test_subset,\n",
    "        iterator=CropsFromTrialsIterator(batch_size, input_time_length, n_preds_per_input, seed),\n",
    "        loss_function=None,\n",
    "        optimizer=None,\n",
    "        model_constraint=None,\n",
    "        monitors=None,\n",
    "        stop_criterion=None,\n",
    "        remember_best_column=remember_best_column,\n",
    "        run_after_early_stop=False,\n",
    "        batch_modifier=None,\n",
    "        do_early_stop=False,\n",
    "        reset_after_second_run=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation acc: 0.8514492753623188, mcc: 0.7013632240527744\n"
     ]
    }
   ],
   "source": [
    "def make_final_predictions(exp, device):\n",
    "    exp.model.eval()\n",
    "    setname = 'test'\n",
    "    dataset = exp.datasets[setname]\n",
    "    preds_per_batch = [var_to_np(exp.model(np_to_var(b[0]).to(device)))\n",
    "                       for b in exp.iterator.get_batches(dataset,\n",
    "                                                         shuffle=False)]\n",
    "    preds_per_trial = compute_preds_per_trial(\n",
    "        preds_per_batch, dataset,\n",
    "        input_time_length=exp.iterator.input_time_length,\n",
    "        n_stride=exp.iterator.n_preds_per_input)\n",
    "    mean_preds_per_trial = [np.mean(preds, axis=(0, 2)) for preds in\n",
    "                            preds_per_trial]\n",
    "    mean_preds_per_trial = np.array(mean_preds_per_trial)\n",
    "    return mean_preds_per_trial, dataset.y\n",
    "        \n",
    "mean_preds_per_trial, y = make_final_predictions(exp, device)\n",
    "preds = np.argmax(mean_preds_per_trial, axis=1)\n",
    "acc = np.sum(preds == y) / len(y)\n",
    "\n",
    "mcc = matthews_corrcoef(y, preds)\n",
    "print(f\"Evaluation acc: {acc}, mcc: {mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemannian-geometry\n",
    "Model korzysta z macierzy kowariancji między kanałami EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimedTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer=transformer\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        t = time.time()\n",
    "        return_value = self.transformer.fit(X=X, y=y)\n",
    "        print(\"{} fitting time: {:.2f}s\".format(self.transformer.__repr__, time.time() - t))\n",
    "        return return_value\n",
    "    \n",
    "    def transform(self, X):\n",
    "        t = time.time()\n",
    "        return_value = self.transformer.transform(X=X)\n",
    "        print(\"{} transforming time: {:.2f}s\".format(self.transformer.__repr__, time.time() - t))\n",
    "        return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_acc(pred_df):\n",
    "    accs = []\n",
    "    for i, d in pred_df.groupby(\"id\"):\n",
    "        accs.append((d.y_pred == d.y_true).mean())\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> fitting time: 5.69s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.44s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.43s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.05s\n",
      "<bound method BaseEstimator.__repr__ of TangentSpace(metric='riemann', tsupdate=False)> transforming time: 0.04s\n",
      "ACC dla zbioru treningowego: 0.8656111929307806, dla zbioru ewaluacyjnego: 0.8586956521739131\n"
     ]
    }
   ],
   "source": [
    "kernel=\"rbf\"\n",
    "adaptation = False\n",
    "C = 10\n",
    "pipe = Pipeline([\n",
    "    (\"ts\", TimedTransformer(TangentSpace(tsupdate=adaptation, metric=\"riemann\"))),\n",
    "    (\"clf\", SVC(kernel=kernel, C=C, probability=True, gamma=\"auto\"))\n",
    "])\n",
    "\n",
    "train_X = np.load(\"data/mean_train_covs.npy\")\n",
    "train_y = np.load(\"data/train_pathology_labels.npy\")\n",
    "test_X = np.load(\"data/mean_eval_covs.npy\")\n",
    "test_y = np.load(\"data/eval_pathology_labels.npy\")\n",
    "fold_i = 1\n",
    "pipe.fit(train_X, train_y)\n",
    "probas_train = pipe.predict_proba(train_X)\n",
    "preds_train = pipe.predict(train_X)\n",
    "train_preds, test_preds, train_probas, test_probas = pd.DataFrame(),pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "column_names = [\"id\", \"y_pred\", \"y_true\"]\n",
    "tmp = pd.DataFrame([len(train_y) * [fold_i], probas_train[:, 1], train_y], index=column_names).T\n",
    "train_probas = train_probas.append(tmp, ignore_index=True)  \n",
    "\n",
    "tmp2 = pd.DataFrame([len(train_y) * [fold_i], preds_train, train_y], index=column_names).T\n",
    "train_preds = train_preds.append(tmp2, ignore_index=True)  \n",
    "\n",
    "probas_test = pipe.predict_proba(test_X)\n",
    "preds_test = pipe.predict(test_X)\n",
    "\n",
    "tmp = pd.DataFrame([len(test_y) * [fold_i], probas_test[:, 1], test_y], index=column_names).T\n",
    "test_probas = test_probas.append(tmp, ignore_index=True)  \n",
    "\n",
    "tmp2 = pd.DataFrame([len(test_y) * [fold_i], preds_test, test_y], index=column_names).T\n",
    "test_preds = test_preds.append(tmp2, ignore_index=True)  \n",
    "\n",
    "print(f\"ACC dla zbioru treningowego: {mean_acc(train_preds)}, dla zbioru ewaluacyjnego: {mean_acc(test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
